### ========================================================================================================================================
## Module       : src/core/types.py
## Author       : Rizky Johan Saputra (Independent Project)
## Date         : 4th November 2025 (Seoul, South Korea)
## Project      : Vision Fusion Real Time System (Copyright 2025)
## Topics       : Computer Vision, Real-Time Systems, Interactive AI System, NLP, Machine Learning and Memory Augmentation
## Purpose      : Provide strongly-typed lightweight core structures used across all pipeline layers
##                (capture, embedding, retrieval, decision). These structures define stable interfaces
##                for frame-level transport, embedding representation, and retrieval output semantics.
## Role         : Typed Core Structures
### ========================================================================================================================================

## ======================================================================================================
## SPECIFICATIONS
## ======================================================================================================
"""
Vision-Fusion-RT — Typed Core Structures
----------------------------------------

These lightweight dataclasses define the standard “contracts” between layers.
Keeping them centralized improves reliability and makes refactors safer.

- Frame: encapsulates a captured image and metadata.
- Emb: a single embedding vector + modality tag + metadata.
- RetrievalResult: final decision for a query, including neighbors and latency.

Notes
- `Frame.data` is BGR (OpenCV convention), uint8 HxWx3.
- Embeddings are float32 arrays; L2-normalized per design (for cosine/IP).
"""

## ======================================================================================================
## SETUP (ADJUSTABLE) (ADJUST IF NECESSARY)
## ======================================================================================================
from __future__ import annotations
from dataclasses import dataclass
from typing import Literal, Optional, Tuple, List, Dict
import numpy as np

## ======================================================================================================
## IMPLEMENTATIONS
## ======================================================================================================
# Assign a dataclass for the frames captured from camera with raw frame and metadata
@dataclass
class Frame:
    # Raw BGR uint8 image (HxWx3)
    data: np.ndarray

    # Timestamp for the captured frame
    ts: float

    # Original capture resolution (W, H)          
    size: Tuple[int, int]         

# Assign a dataclass for the single embedding vector generated by vision and text encoders
@dataclass
class Emb:
    # L2-normalized embedding vector (Float32)
    vec: np.ndarray

    # Embedding modality type
    modality: Literal["image", "text"]

    # Metadata dictionary describing this embedding (Source, ts, etc)
    meta: Dict                    

# Assign a dataclass for the final retrieval results from inference pass
@dataclass
class RetrievalResult:
    # Predicted label (String label of best match or "unknown")
    label: str

    # Confidence score (After fusion, EMA, open-set handling)
    score: float

    # Neighbor list (Debugging / visualization / introspection friendly)
    neighbors: List[tuple] 

    # Duration of this inference step in milliseconds
    latency_ms: float

### ========================================================================================================================================
## END (ADD IMPLEMENTATIONS IF NECESSARY)
### ========================================================================================================================================